{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# PyTorch\n",
        "!pip install torch torchvision\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch import nn\n",
        "\n",
        "# Regular imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import json\n",
        "import copy\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5szrs1S2rZqZ",
        "outputId": "2179fc5d-5973-4f30-ac2e-455f9107ac58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRlaLoWequZ0"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 25\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "\n",
        "class RLM(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        with open('/content/drive/MyDrive/Master 1/Projet TER/Data/xT_new.json', 'r') as file:\n",
        "            self.target = torch.tensor(json.load(file))\n",
        "        with open('/content/drive/MyDrive/Master 1/Projet TER/Data/RLMs_per_sequence_home_1.json', 'r') as file:\n",
        "            #print(json.load(file))\n",
        "            self.home_1 = torch.tensor(json.load(file))\n",
        "        with open('/content/drive/MyDrive/Master 1/Projet TER/Data/RLMs_per_sequence_away_1 old.json', 'r') as file:\n",
        "            self.away_1 = torch.tensor(json.load(file))\n",
        "        with open('/content/drive/MyDrive/Master 1/Projet TER/Data/RLMs_per_sequence_home_2 old.json', 'r') as file:\n",
        "            self.home_2 = torch.tensor(json.load(file))\n",
        "        with open('/content/drive/MyDrive/Master 1/Projet TER/Data/RLMs_per_sequence_away_2 old.json', 'r') as file:\n",
        "            self.away_2 = torch.tensor(json.load(file))\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        return self.away_1[index], self.away_2[index], self.home_1[index], self.home_2[index], self.target[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target)\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "                    #out_channels too big add conv between, circular padding mode\n",
        "                    nn.Conv2d(in_channels=4, out_channels=32, kernel_size=5, stride=3, padding=2),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "                    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=2),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(kernel_size=(2,2), stride=1, padding=1))\n",
        "        conv_output_size = self._get_conv_output_size()\n",
        "        self.fc1 = nn.Linear(conv_output_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "\n",
        "    def _get_conv_output_size(self):\n",
        "        # Dummy forward pass to get the output size of the last convolutional layer\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, 4, 15, 120)\n",
        "            conv_output = self.layer(dummy_input)\n",
        "            conv_output_size = conv_output.view(conv_output.size(0), -1).size(1)\n",
        "\n",
        "        return conv_output_size\n",
        "\n",
        "    def forward(self, home_1, home_2, away_1, away_2):\n",
        "        # Stack input tensors along the channel dimension\n",
        "        x = torch.stack([home_1, home_2, away_1, away_2], dim=1)\n",
        "        x = self.layer(x)\n",
        "\n",
        "        # Flatten the output for fully connected layers\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "\n",
        "        # Apply fully connected layers with activation functions\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def run(train_loader, val_loader, test_loader, device):\n",
        "    model = CNN()\n",
        "    model.to(device)\n",
        "    criterion = nn.MSELoss() # Mean Square Error\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # Keep the best model\n",
        "    best_mse = np.inf\n",
        "    best_weights = None\n",
        "    training_loss_history = []\n",
        "    mse_history = []\n",
        "\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{NUM_EPOCHS}]:')\n",
        "\n",
        "        for i, (away_1, away_2, home_1, home_2, y_batch) in enumerate(train_loader):\n",
        "\n",
        "            away_1, away_2, home_1, home_2, y_batch = away_1.to(device), away_2.to(device), home_1.to(device), home_2.to(device), y_batch.to(device)\n",
        "\n",
        "            # Assuming y_batch has shape [8], reshape it to [8, 1] or [8, 2] based on your needs\n",
        "            y_batch = y_batch.unsqueeze(1)  # Reshape to [8, 1] if necessary\n",
        "\n",
        "            # Forward pass\n",
        "            y_pred = model(home_1, home_2, away_1, away_2)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            print(f'\\tTraining Loss (MSE): {round(float(loss), 6)}')\n",
        "            training_loss_history.append(loss)\n",
        "\n",
        "            # Clear gradients w.r.t. parameters\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "\n",
        "            # Perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation after each epoch\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for away_1, away_2, home_1, home_2, y_batch in val_loader:\n",
        "\n",
        "                away_1, away_2, home_1, home_2, y_batch = away_1.to(device), away_2.to(device), home_1.to(device), home_2.to(device), y_batch.to(device)\n",
        "\n",
        "                # Assuming y_batch has shape [8], reshape it to [8, 1] or [8, 2] based on your needs\n",
        "                y_batch = y_batch.unsqueeze(1)  # Reshape to [8, 1] if necessary\n",
        "\n",
        "                # Forward pass\n",
        "                y_pred = model(home_1, home_2, away_1, away_2)\n",
        "\n",
        "                # Compute the MSE (reduction='mean' by default)\n",
        "                mse = criterion(y_pred, y_batch)\n",
        "                mse = float(mse)\n",
        "\n",
        "                mse_history.append(mse)\n",
        "\n",
        "                # Update MSE values\n",
        "                if mse < best_mse:\n",
        "                    best_mse = mse\n",
        "                    best_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "                print(f'\\tValidation Loss (MSE): {round(float(mse), 6)}')\n",
        "\n",
        "                # Clear gradients w.r.t. parameters\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    print('Training finished.')\n",
        "\n",
        "    torch.save(model.state_dict(), 'delta_xt_prediction_model_mse.pth')\n",
        "\n",
        "    print(\"Best MSE: %.6f\" % best_mse)\n",
        "    #print(\"RMSE: %.4f\" % np.sqrt(best_mse))\n",
        "    plt.plot(mse_history)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # Test\n",
        "    for away_1, away_2, home_1, home_2, y_batch in test_loader:\n",
        "\n",
        "        away_1, away_2, home_1, home_2, y_batch = away_1.to(device), away_2.to(device), home_1.to(device), home_2.to(device), y_batch.to(device)\n",
        "\n",
        "        # Assuming y_batch has shape [8], reshape it to [8, 1] or [8, 2] based on your needs\n",
        "        y_batch = y_batch.unsqueeze(1)  # Reshape to [8, 1] if necessary\n",
        "\n",
        "        y_pred = model(home_1, home_2, away_1, away_2)\n",
        "\n",
        "        print('Delta xT Values (predicted | ground truth | delta):')\n",
        "        for index in range(len(y_batch)):\n",
        "            print(f'{round(float(y_pred[index, 0]), 6)} | {round(float(y_batch[index]), 6)} | {round(abs(float(y_pred[index, 0]) - float(y_batch[index])), 6)}')\n",
        "\n",
        "        y_pred_array = y_pred.detach().numpy()\n",
        "        y_pred_array = y_pred_array[:, 0]\n",
        "        y_batch_array = y_batch.detach().numpy()[:, 0]\n",
        "\n",
        "        mean_delta = np.abs(np.average(y_pred_array - y_batch_array))\n",
        "        print(f'\\nMean Delta = {round(float(mean_delta), 6)}')\n",
        "\n",
        "\n",
        "        std = np.std(np.array([y_pred_array, y_batch_array]))\n",
        "        print(f'Standard Deviation = {round(float(std), 6)}')\n",
        "\n",
        "        var = pow(std, 2)\n",
        "        print(f'Variance = {round(float(var), 8)}')\n",
        "\n",
        "        plt.scatter(y_pred_array, y_batch_array)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    # restore model and return best accuracy\n",
        "    print(model.load_state_dict(best_weights))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "dataset = RLM()\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.10 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "# Use random_split to split the dataset\n",
        "#torch.manual_seed(42)  # You can use any integer value as the seed\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(dataset.home_1.shape)\n",
        "print(dataset.target.shape)\n",
        "\n",
        "run(train_loader, val_loader, test_loader, device)"
      ],
      "metadata": {
        "id": "E-_fZBvhu1ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-mAz-kVOfOX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
